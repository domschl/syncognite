<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.3"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Syncognite: syncognite - A neural network library inspired by Stanford&#39;s CS231n course</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">Syncognite
   </div>
   <div id="projectbrief">A neural network library for convolutional, fully connected nets and RNNs in C++.</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.3 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search",'Search','.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

</div><!-- top -->
<div><div class="header">
  <div class="headertitle"><div class="title">syncognite - A neural network library inspired by Stanford's CS231n course </div></div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p ><a href="https://github.com/domschl/syncognite/actions"><img src="https://github.com/domschl/syncognite/workflows/CMake/badge.svg" alt="Cmake" style="pointer-events: none;" class="inline"/></a> [<img src="http://img.shields.io/badge/license-MIT-brightgreen.svg?style=flat" alt="License" style="pointer-events: none;" class="inline"/>](LICENSE)</p>
<p >A neural network library for convolutional, fully connected nets and RNNs in C++.</p>
<p >The current <code>v2</code>-version of the project has the following objectives:</p><ul>
<li>remove CUDA and other external graphics card libs (since for good performance they need to rely on blackbox-libs)</li>
<li>implement full support for graphs (not only sequenctial)</li>
<li>This will be work-in-progress for considerable time. The previous version is archived in branch <a href="https://github.com/domschl/syncognite/tree/v1"><code>v1</code></a>.</li>
</ul>
<p >This library implements some of the assignments from Stanfords's <a href="http://cs231n.stanford.edu/index.html">CS231n</a> 2016 course by Andrej Karpathy, Fei-Fei Li, Justin Johnson and <a href="http://cs224d.stanford.edu/index.html">CS224d</a> by Richard Socher as C++ framework.</p>
<p >Current state: <b>beta</b></p>
<h2><a class="anchor" id="autotoc_md1"></a>
Features</h2>
<ul>
<li>Fully connected networks</li>
<li>Convolutional layers</li>
<li>Recurrent nets (RNNs)</li>
<li>Long-term short-term memory nets (LSTMs)</li>
<li>ReLu, Sigmoid, TanH, SELU&lt;sup&gt;(1), resilu&lt;sup&gt;(2) nonlinearities</li>
<li>BatchNorm, SpatialBatchNorm, Dropout layers</li>
<li>Softmax, SVM loss</li>
<li>TemporalAffine and TemporalSoftmax layers for RNNs</li>
</ul>
<p >[1]: "scaled exponential linear units" (SELUs), <a href="https://arxiv.org/abs/1706.02515">https://arxiv.org/abs/1706.02515</a></p>
<p >[2]: "resilu residual &amp; relu nonlinearity + linearity" (linear skip connection combined with non-linearity) (<a href="https://github.com/domschl/syncognite#resilu-non--linearity">s.b.</a>)</p>
<h1><a class="anchor" id="autotoc_md2"></a>
Sample</h1>
<h2><a class="anchor" id="autotoc_md3"></a>
Model</h2>
<p >Example: C++ definition of a deep convolutional net with batch-norm, dropout and fully connected layers:</p>
<div class="fragment"><div class="line">LayerBlock lb(R<span class="stringliteral">&quot;({&quot;name&quot;:&quot;DomsNet&quot;,&quot;bench&quot;:false,&quot;init&quot;:&quot;orthonormal&quot;})&quot;_json);</span></div>
<div class="line"><span class="stringliteral"></span> </div>
<div class="line"><span class="stringliteral">lb.addLayer(</span><span class="stringliteral">&quot;Convolution&quot;</span>, <span class="stringliteral">&quot;cv1&quot;</span>, R<span class="stringliteral">&quot;({&quot;inputShape&quot;:[1,28,28],&quot;kernel&quot;:[48,5,5],&quot;stride&quot;:1,&quot;pad&quot;:2})&quot;,{&quot;input&quot;});</span></div>
<div class="line"><span class="stringliteral">lb.addLayer(&quot;BatchNorm&quot;,&quot;sb1&quot;,&quot;{}&quot;,{&quot;cv1&quot;});</span></div>
<div class="line"><span class="stringliteral">lb.addLayer(&quot;Relu&quot;,&quot;rl1&quot;,&quot;{}&quot;,{&quot;sb1&quot;});</span></div>
<div class="line"><span class="stringliteral">lb.addLayer(&quot;Dropout&quot;,&quot;doc1&quot;,R&quot;({&quot;drop&quot;:0.8})&quot;,{&quot;rl1&quot;});</span></div>
<div class="line"><span class="stringliteral">lb.addLayer(&quot;Convolution&quot;, &quot;cv2&quot;, R&quot;({&quot;kernel&quot;:[48,3,3],&quot;stride&quot;:1,&quot;pad&quot;:1})&quot;,{&quot;doc1&quot;});</span></div>
<div class="line"><span class="stringliteral">lb.addLayer(&quot;Relu&quot;,&quot;rl2&quot;,&quot;{}&quot;,{&quot;cv2&quot;});</span></div>
<div class="line"><span class="stringliteral">lb.addLayer(&quot;Convolution&quot;, &quot;cv3&quot;, R&quot;({&quot;kernel&quot;:[64,3,3],&quot;stride&quot;:2,&quot;pad&quot;:1})&quot;,{&quot;rl2&quot;});</span></div>
<div class="line"><span class="stringliteral">lb.addLayer(&quot;BatchNorm&quot;,&quot;sb2&quot;,&quot;{}&quot;,{&quot;cv3&quot;});</span></div>
<div class="line"><span class="stringliteral">lb.addLayer(&quot;Relu&quot;,&quot;rl3&quot;,&quot;{}&quot;,{&quot;sb2&quot;});</span></div>
<div class="line"><span class="stringliteral">lb.addLayer(&quot;Dropout&quot;,&quot;doc2&quot;,R&quot;({&quot;drop&quot;:0.8})&quot;,{&quot;rl3&quot;});</span></div>
<div class="line"><span class="stringliteral">lb.addLayer(&quot;Convolution&quot;, &quot;cv4&quot;, R&quot;({&quot;kernel&quot;:[64,3,3],&quot;stride&quot;:1,&quot;pad&quot;:1})&quot;,{&quot;doc2&quot;});</span></div>
<div class="line"><span class="stringliteral">lb.addLayer(&quot;Relu&quot;,&quot;rl4&quot;,&quot;{}&quot;,{&quot;cv4&quot;});</span></div>
<div class="line"><span class="stringliteral">lb.addLayer(&quot;Convolution&quot;, &quot;cv5&quot;, R&quot;({&quot;kernel&quot;:[128,3,3],&quot;stride&quot;:2,&quot;pad&quot;:1})&quot;,{&quot;rl4&quot;});</span></div>
<div class="line"><span class="stringliteral">lb.addLayer(&quot;BatchNorm&quot;,&quot;sb3&quot;,&quot;{}&quot;,{&quot;cv5&quot;});</span></div>
<div class="line"><span class="stringliteral">lb.addLayer(&quot;Relu&quot;,&quot;rl5&quot;,&quot;{}&quot;,{&quot;sb3&quot;});</span></div>
<div class="line"><span class="stringliteral">lb.addLayer(&quot;Dropout&quot;,&quot;doc3&quot;,R&quot;({&quot;drop&quot;:0.8})&quot;,{&quot;rl5&quot;});</span></div>
<div class="line"><span class="stringliteral">lb.addLayer(&quot;Convolution&quot;, &quot;cv6&quot;, R&quot;({&quot;kernel&quot;:[128,3,3],&quot;stride&quot;:1,&quot;pad&quot;:1})&quot;,{&quot;doc3&quot;});</span></div>
<div class="line"><span class="stringliteral">lb.addLayer(&quot;Relu&quot;,&quot;rl6&quot;,&quot;{}&quot;,{&quot;cv6&quot;});</span></div>
<div class="line"><span class="stringliteral"></span> </div>
<div class="line"><span class="stringliteral">lb.addLayer(&quot;Affine&quot;,&quot;af1&quot;,R&quot;({&quot;hidden&quot;:1024})&quot;,{&quot;rl6&quot;});</span></div>
<div class="line"><span class="stringliteral">lb.addLayer(&quot;BatchNorm&quot;,&quot;bn1&quot;,&quot;{}&quot;,{&quot;af1&quot;});</span></div>
<div class="line"><span class="stringliteral">lb.addLayer(&quot;Relu&quot;,&quot;rla1&quot;,&quot;{}&quot;,{&quot;bn1&quot;});</span></div>
<div class="line"><span class="stringliteral">lb.addLayer(&quot;Dropout&quot;,&quot;do1&quot;,R&quot;({&quot;drop&quot;:0.7})&quot;,{&quot;rla1&quot;});</span></div>
<div class="line"><span class="stringliteral">lb.addLayer(&quot;Affine&quot;,&quot;af2&quot;,R&quot;({&quot;hidden&quot;:512})&quot;,{&quot;do1&quot;});</span></div>
<div class="line"><span class="stringliteral">lb.addLayer(&quot;BatchNorm&quot;,&quot;bn2&quot;,&quot;{}&quot;,{&quot;af2&quot;});</span></div>
<div class="line"><span class="stringliteral">lb.addLayer(&quot;Relu&quot;,&quot;rla2&quot;,&quot;{}&quot;,{&quot;bn2&quot;});</span></div>
<div class="line"><span class="stringliteral">lb.addLayer(&quot;Dropout&quot;,&quot;do2&quot;,R&quot;({&quot;drop&quot;:0.7})&quot;,{&quot;rla2&quot;});</span></div>
<div class="line"><span class="stringliteral">lb.addLayer(&quot;Affine&quot;,&quot;af3&quot;,R&quot;({&quot;hidden&quot;:10})&quot;,{&quot;do2&quot;});</span></div>
<div class="line"><span class="stringliteral">lb.addLayer(&quot;Softmax&quot;,&quot;sm1&quot;,&quot;{}&quot;,{&quot;af3&quot;});</span></div>
</div><!-- fragment --><h2><a class="anchor" id="autotoc_md4"></a>
Training</h2>
<div class="fragment"><div class="line">json jo(R<span class="stringliteral">&quot;({&quot;verbose&quot;:true,&quot;shuffle&quot;:true,&quot;lr_decay&quot;:0.95,&quot;epsilon&quot;:1e-8})&quot;_json);</span></div>
<div class="line"><span class="stringliteral">jo[</span><span class="stringliteral">&quot;epochs&quot;</span>]=(floatN)40.0;</div>
<div class="line">jo[<span class="stringliteral">&quot;batch_size&quot;</span>]=50;</div>
<div class="line">jo[<span class="stringliteral">&quot;learning_rate&quot;</span>]=(floatN)5e-4;</div>
<div class="line">jo[<span class="stringliteral">&quot;regularization&quot;</span>]=(floatN)1e-8;</div>
<div class="line"> </div>
<div class="line">lb.train(X, y, Xv, yv, <span class="stringliteral">&quot;Adam&quot;</span>, jo);</div>
<div class="line"> </div>
<div class="line">floatN train_err, val_err, test_err;</div>
<div class="line">train_err=lb.test(X, y, jo.value(<span class="stringliteral">&quot;batch_size&quot;</span>, 50));</div>
<div class="line">val_err=lb.test(Xv, yv, jo.value(<span class="stringliteral">&quot;batch_size&quot;</span>, 50));</div>
<div class="line">test_err=lb.test(Xt, yt, jo.value(<span class="stringliteral">&quot;batch_size&quot;</span>, 50));</div>
<div class="line"> </div>
<div class="line">cerr &lt;&lt; <span class="stringliteral">&quot;Final results on MNIST after &quot;</span> &lt;&lt; jo.value(<span class="stringliteral">&quot;epochs&quot;</span>,(floatN)0.0) &lt;&lt; <span class="stringliteral">&quot; epochs:&quot;</span> &lt;&lt; endl;</div>
<div class="line">cerr &lt;&lt; <span class="stringliteral">&quot;      Train-error: &quot;</span> &lt;&lt; train_err &lt;&lt; <span class="stringliteral">&quot; train-acc: &quot;</span> &lt;&lt; 1.0-train_err &lt;&lt; endl;</div>
<div class="line">cerr &lt;&lt; <span class="stringliteral">&quot; Validation-error: &quot;</span> &lt;&lt; val_err &lt;&lt;   <span class="stringliteral">&quot;   val-acc: &quot;</span> &lt;&lt; 1.0-val_err &lt;&lt; endl;</div>
<div class="line">cerr &lt;&lt; <span class="stringliteral">&quot;       Test-error: &quot;</span> &lt;&lt; test_err &lt;&lt;  <span class="stringliteral">&quot;  test-acc: &quot;</span> &lt;&lt; 1.0-test_err &lt;&lt; endl;</div>
</div><!-- fragment --><p >see <a href="cpmnist/">mnisttest</a> or <a href="cpcifar10/">cifar10test</a> for complete examples.</p>
<h2><a class="anchor" id="autotoc_md5"></a>
A model that generates text via LSTMs can be defined with:</h2>
<div class="fragment"><div class="line">json j0;</div>
<div class="line"><span class="keywordtype">string</span> oName{<span class="stringliteral">&quot;OH0&quot;</span>};</div>
<div class="line">j0[<span class="stringliteral">&quot;inputShape&quot;</span>]=vector&lt;int&gt;{T};</div>
<div class="line">j0[<span class="stringliteral">&quot;V&quot;</span>]=VS;</div>
<div class="line">lb.addLayer(<span class="stringliteral">&quot;OneHot&quot;</span>,oName,j0,{<span class="stringliteral">&quot;input&quot;</span>});</div>
<div class="line"> </div>
<div class="line"><span class="keywordtype">int</span> layer_depth=4;</div>
<div class="line"><span class="keywordtype">string</span> nName;</div>
<div class="line">json j1;</div>
<div class="line">j1[<span class="stringliteral">&quot;inputShape&quot;</span>]=vector&lt;int&gt;{VS,T};</div>
<div class="line">j1[<span class="stringliteral">&quot;N&quot;</span>]=BS;</div>
<div class="line">j1[<span class="stringliteral">&quot;H&quot;</span>]=H;</div>
<div class="line">j1[<span class="stringliteral">&quot;forgetgateinitones&quot;</span>]=<span class="keyword">true</span>;</div>
<div class="line">j1[<span class="stringliteral">&quot;forgetbias&quot;</span>]=1.0;</div>
<div class="line">j1[<span class="stringliteral">&quot;clip&quot;</span>]=clip;</div>
<div class="line"><span class="keywordflow">for</span> (<span class="keyword">auto</span> l=0; l&lt;layer_depth; l++) {</div>
<div class="line">    nName=<span class="stringliteral">&quot;lstm&quot;</span>+std::to_string(l);</div>
<div class="line">    lb.addLayer(rnntype,nName,j1,{oName});</div>
<div class="line">    oName=nName;</div>
<div class="line">}</div>
<div class="line"> </div>
<div class="line">json j11;</div>
<div class="line">j11[<span class="stringliteral">&quot;inputShape&quot;</span>]=vector&lt;int&gt;{VS,T};</div>
<div class="line">lb.addLayer(<span class="stringliteral">&quot;TemporalSoftmax&quot;</span>,<span class="stringliteral">&quot;sm1&quot;</span>,j11,{<span class="stringliteral">&quot;af1&quot;</span>});</div>
</div><!-- fragment --><p> see <a href="rnnreader/">rnnreader</a> for a complete example.</p>
<h1><a class="anchor" id="autotoc_md6"></a>
Dependencies:</h1>
<ul>
<li>C++ 11 compiler (on Linux (tested: clang, gcc, Intel icpc) or macOS (clang x86-64 and Apple silicon (clang 12, 13)), Raspberry ARM(gcc))</li>
<li>CMake build system.</li>
<li><a href="https://support.hdfgroup.org/HDF5/">Hdf5</a> <a href="https://support.hdfgroup.org/HDF5/doc/cpplus_RM/">C++ API</a> for model saving and sample data, <code>hdf5</code> or <code>libhdf5-dev</code>.</li>
</ul>
<h2><a class="anchor" id="autotoc_md7"></a>
Apple silicon notes</h2>
<ul>
<li>use <code>ccmake</code> to configure <code>USE_SYSTEM_BLAS</code> to <code>ON</code>, which instructs eigen to use M1's hardware accelerators. <code>rnnreader</code> sees dramatic 3x-6x speedup, single thread benchmarks in <code>bench</code> see 200%-400% improvements! [Testet on macOS 12 beta 3 - 2021-07-19]</li>
<li>Memory: macOS simply doesn't give processes all available memory. Expect swapping (and significant speed decrease) when allocating more than 4-5GB, even on 16GB M1 machines.</li>
<li>The hdf5 libraries are available for ARM64 (<code>brew install hdf5</code>).</li>
</ul>
<h2><a class="anchor" id="autotoc_md8"></a>
External libraries that are included in the source tree:</h2>
<ul>
<li><a href="http://eigen.tuxfamily.org/">Eigen</a> v3.4 <code>eigen3</code>, already (in default configuration) included in the source tree as submodule.</li>
<li><a href="https://github.com/nlohmann/json">nlohmann_json</a>, already included in source tree (cpneural/nlohmann_json).</li>
</ul>
<h1><a class="anchor" id="autotoc_md9"></a>
Build</h1>
<p >syncognite uses the CMake build system.</p>
<p >Clone the repository:</p>
<div class="fragment"><div class="line">git clone git://github.com/domschl/syncognite</div>
<div class="line">git submodule init</div>
<div class="line">git submodule update    # This gets the in-tree Eigen3</div>
</div><!-- fragment --><p >Create a <code>build</code> directory within the syncognite directory and configure the build:</p>
<div class="fragment"><div class="line"># in sycognite/build, default is make-build-system, but Ninja can also be used:</div>
<div class="line">cmake [-G Ninja] ..</div>
<div class="line"># optionally use ccmake to configure options and paths:</div>
<div class="line">ccmake ..</div>
</div><!-- fragment --><p >To configure your editor / ide for include paths use (in <code>build</code>):</p>
<div class="fragment"><div class="line">cmake -DCMAKE_EXPORT_COMPILE_COMMANDS=YES ..</div>
</div><!-- fragment --><p> or simply execute the helper <code>create_compile_commands.sh</code>.</p>
<p >macOS users might want to configure for building with Xcode:</p>
<div class="fragment"><div class="line">cmake -G Xcode ..</div>
</div><!-- fragment --><p >Build the project:</p>
<div class="fragment"><div class="line">make</div>
<div class="line"># or</div>
<div class="line">ninja</div>
<div class="line"># or (macOS) start Xcode and load the generated project file.</div>
</div><!-- fragment --><h1><a class="anchor" id="autotoc_md10"></a>
History</h1>
<ul>
<li>2022-03-22: Started v2-branch Removed CUDA and other external graphics libs.</li>
<li>2021-10-10: Moved CI from travis (defunct) to github workflows. Valgrind currently disabled.</li>
<li>2021-08-21: eigen update to 3.4 release</li>
<li>2021-07-19: eigen update to 3.4rc1</li>
<li>2021-07-19: Dramatic speed improvements when configuring eigen to use system blas (using <code>ccmake</code>) with Apple M1, seems to use M1's magic hardware accelerators.</li>
<li>2020-11-12: Switched eigen3 submodule to <a href="https://gitlab.com/libeigen/eigen">gitlab</a>, tracks 3.3 branch</li>
<li>2020-07-31: Apple ARM tested ok.</li>
<li>2020-07-05: Tests with resilu (non-)linearity</li>
<li>2018-03-02: Removed faulty RAN layer, switched to official eigen3 github-mirror at: <a href="https://github.com/eigenteam/eigen-git-mirror">Github eigen3</a>, fixes for eigen-dev stricted type-checking.</li>
</ul>
<h1><a class="anchor" id="autotoc_md11"></a>
Subprojects:</h1>
<p >Things that should work:</p>
<ul>
<li><a href="cptest/">testneural</a> (cptest subproject, consistency tests for all layers using testdata and numerical differentials)</li>
<li><a href="bench/">bench</a> (benchmark subproject, benchmarks for all layers)</li>
<li><a href="cpmnist/">mnisttest</a> (cpmnist subproject, MNIST handwritten digit recognition with a convolutional network, requires <a href="datasets/">dataset download</a>.)</li>
<li><a href="cpcifar10/">cifar10test</a> (cpcifar10 subproject, cifar10 image recognition with a convolutional network, requires <a href="datasets/">dataset download</a>.)</li>
<li><a href="rnnreader/">rnnreader</a> (rnnreader subproject, text generation via RNN/LSTMs, similar to char-rnn.)</li>
</ul>
<h1><a class="anchor" id="autotoc_md12"></a>
Appendix</h1>
<h2><a class="anchor" id="autotoc_md13"></a>
Resilu (non-) linearity</h2>
<p >See <a href="https://github.com/domschl/syncognite/blob/master/doc/resilu-linearity.ipynb">jupyter notebook</a> for visualization and more discussions of resilu function.</p>
<p >(1) <img src="https://render.githubusercontent.com/render/math?math=rsi(x)=\frac{x}{1-e^{-x}}" alt="" class="inline"/></p>
<p ><img src="https://render.githubusercontent.com/render/math?math=rsi(x)" alt="" class="inline"/> can be rewritten as:</p>
<p >(2) <img src="https://render.githubusercontent.com/render/math?math=rsi(x)=\frac{x}{e^{x}-1}%2Bx" alt="" class="inline"/></p>
<p >thus can be interpreted as a residual combination of linearity and non-linearity via addition.</p>
<p >Since <img src="https://render.githubusercontent.com/render/math?math=rsi(x)" alt="" class="inline"/> shows a phase-transition instability at <img src="https://render.githubusercontent.com/render/math?math=x=0" alt="" class="inline"/>, a taylor <img src="https://render.githubusercontent.com/render/math?math=O(4)" alt="" class="inline"/> approximation is used for <img src="https://render.githubusercontent.com/render/math?math=rsi(x)" alt="" class="inline"/> and <img src="https://render.githubusercontent.com/render/math?math=%5Cnabla rsi(x)" alt="" class="inline"/> for <img src="https://render.githubusercontent.com/render/math?math=-h%20%3C%200%20%3C%20h" alt="" class="inline"/>.</p>
<p >Both <img src="https://render.githubusercontent.com/render/math?math=e%5E%7Bx%7D" alt="" class="inline"/> quotients (1) and (2) have as limit relu(x) or, in case of (2): -relu(x), if <img src="https://render.githubusercontent.com/render/math?math=e%5E%7Bx%7D" alt="" class="inline"/> is replaced by <img src="https://render.githubusercontent.com/render/math?math=e%5E%7B%5Cfrac%7Bx%7D%7Ba%7D%7D" alt="" class="inline"/> for small constants a. </p>
</div></div><!-- contents -->
</div><!-- PageDoc -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.3
</small></address>
</body>
</html>
